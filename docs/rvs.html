<!DOCTYPE html>
<html lang="en-gb" xml:lang="en-gb">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Random variables | STAT0002 Introduction to Probability and Statistics</title>
  <meta name="description" content="Produces STAT0002 notes in an accessible format" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Random variables | STAT0002 Introduction to Probability and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Produces STAT0002 notes in an accessible format" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Random variables | STAT0002 Introduction to Probability and Statistics" />
  
  <meta name="twitter:description" content="Produces STAT0002 notes in an accessible format" />
  

<meta name="author" content="Paul Northrop" />


<meta name="date" content="2024-03-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="more-probability.html"/>
<link rel="next" href="simple.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STAT0002 2022-23</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>The purpose of these notes</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#real"><i class="fa fa-check"></i><b>1.1</b> Real statistical investigations</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#shuttle"><i class="fa fa-check"></i><b>1.2</b> Challenger Space Shuttle Catastrophe</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#uncertainty"><i class="fa fa-check"></i><b>1.2.1</b> Uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#a-very-brief-introduction-to-stochastic-simulation"><i class="fa fa-check"></i><b>1.3</b> A very brief introduction to stochastic simulation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="descriptive.html"><a href="descriptive.html"><i class="fa fa-check"></i><b>2</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descriptive.html"><a href="descriptive.html#types-of-data"><i class="fa fa-check"></i><b>2.1</b> Types of data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="descriptive.html"><a href="descriptive.html#qualitative-or-categorical-data"><i class="fa fa-check"></i><b>2.1.1</b> Qualitative or categorical data</a></li>
<li class="chapter" data-level="2.1.2" data-path="descriptive.html"><a href="descriptive.html#quantitative-or-numerical-data"><i class="fa fa-check"></i><b>2.1.2</b> Quantitative or numerical data</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="descriptive.html"><a href="descriptive.html#describing-distributions"><i class="fa fa-check"></i><b>2.2</b> Describing distributions</a>
<ul>
<li class="chapter" data-level="" data-path="descriptive.html"><a href="descriptive.html#example-oxford-births-data"><i class="fa fa-check"></i>Example: Oxford births data</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="descriptive.html"><a href="descriptive.html#summary-statistics"><i class="fa fa-check"></i><b>2.3</b> Summary statistics</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="descriptive.html"><a href="descriptive.html#fivenumber"><i class="fa fa-check"></i><b>2.3.1</b> Five number summary</a></li>
<li class="chapter" data-level="2.3.2" data-path="descriptive.html"><a href="descriptive.html#meanstdev"><i class="fa fa-check"></i><b>2.3.2</b> Mean and standard deviation</a></li>
<li class="chapter" data-level="2.3.3" data-path="descriptive.html"><a href="descriptive.html#mode"><i class="fa fa-check"></i><b>2.3.3</b> Mode</a></li>
<li class="chapter" data-level="2.3.4" data-path="descriptive.html"><a href="descriptive.html#symmetry"><i class="fa fa-check"></i><b>2.3.4</b> Symmetry</a></li>
<li class="chapter" data-level="2.3.5" data-path="descriptive.html"><a href="descriptive.html#corr1"><i class="fa fa-check"></i><b>2.3.5</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="descriptive.html"><a href="descriptive.html#tables"><i class="fa fa-check"></i><b>2.4</b> Tables</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="descriptive.html"><a href="descriptive.html#frequency-distribution"><i class="fa fa-check"></i><b>2.4.1</b> Frequency distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="descriptive.html"><a href="descriptive.html#graphs"><i class="fa fa-check"></i><b>2.5</b> Graphs (1 variable)</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="descriptive.html"><a href="descriptive.html#histogram"><i class="fa fa-check"></i><b>2.5.1</b> Histograms</a></li>
<li class="chapter" data-level="2.5.2" data-path="descriptive.html"><a href="descriptive.html#stem"><i class="fa fa-check"></i><b>2.5.2</b> Stem-and-leaf plots</a></li>
<li class="chapter" data-level="2.5.3" data-path="descriptive.html"><a href="descriptive.html#dotplots"><i class="fa fa-check"></i><b>2.5.3</b> Dotplots</a></li>
<li class="chapter" data-level="2.5.4" data-path="descriptive.html"><a href="descriptive.html#boxplots"><i class="fa fa-check"></i><b>2.5.4</b> Boxplots</a></li>
<li class="chapter" data-level="2.5.5" data-path="descriptive.html"><a href="descriptive.html#barplots"><i class="fa fa-check"></i><b>2.5.5</b> Barplots</a></li>
<li class="chapter" data-level="2.5.6" data-path="descriptive.html"><a href="descriptive.html#times-series-plots"><i class="fa fa-check"></i><b>2.5.6</b> Times series plots</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="descriptive.html"><a href="descriptive.html#election"><i class="fa fa-check"></i><b>2.6</b> 2000 US presidential election</a></li>
<li class="chapter" data-level="2.7" data-path="descriptive.html"><a href="descriptive.html#graphs2"><i class="fa fa-check"></i><b>2.7</b> Graphs (2 variables)</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="descriptive.html"><a href="descriptive.html#scatter-plots"><i class="fa fa-check"></i><b>2.7.1</b> Scatter plots</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="descriptive.html"><a href="descriptive.html#transformation"><i class="fa fa-check"></i><b>2.8</b> Transformation of data</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="descriptive.html"><a href="descriptive.html#transsymmetry"><i class="fa fa-check"></i><b>2.8.1</b> Transformation to approximate symmetry</a></li>
<li class="chapter" data-level="2.8.2" data-path="descriptive.html"><a href="descriptive.html#straighten"><i class="fa fa-check"></i><b>2.8.2</b> Straightening scatter plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#sids"><i class="fa fa-check"></i><b>3.1</b> Misleading statistical evidence in cot death trials</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#relative-frequency-definition-of-probability"><i class="fa fa-check"></i><b>3.2</b> Relative frequency definition of probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#basic-properties-of-probability"><i class="fa fa-check"></i><b>3.3</b> Basic properties of probability</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>3.4</b> Conditional probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#addition-rule-of-probability"><i class="fa fa-check"></i><b>3.5</b> Addition rule of probability</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="probability.html"><a href="probability.html#mutually-exclusive-events"><i class="fa fa-check"></i><b>3.5.1</b> Mutually exclusive events</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#multrule"><i class="fa fa-check"></i><b>3.6</b> Multiplication rule of probability</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#indepevents"><i class="fa fa-check"></i><b>3.7</b> Independence of events</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="probability.html"><a href="probability.html#bloodindep"><i class="fa fa-check"></i><b>3.7.1</b> An example of independence</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="more-probability.html"><a href="more-probability.html"><i class="fa fa-check"></i><b>4</b> More probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="more-probability.html"><a href="more-probability.html#law-of-total-probability"><i class="fa fa-check"></i><b>4.1</b> Law of total probability</a></li>
<li class="chapter" data-level="4.2" data-path="more-probability.html"><a href="more-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.2</b> Bayes’ theorem</a></li>
<li class="chapter" data-level="4.3" data-path="more-probability.html"><a href="more-probability.html#dna-identification-evidence"><i class="fa fa-check"></i><b>4.3</b> DNA identification evidence</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="rvs.html"><a href="rvs.html"><i class="fa fa-check"></i><b>5</b> Random variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="rvs.html"><a href="rvs.html#discrete"><i class="fa fa-check"></i><b>5.1</b> Discrete random variables</a></li>
<li class="chapter" data-level="5.2" data-path="rvs.html"><a href="rvs.html#continuous"><i class="fa fa-check"></i><b>5.2</b> Continuous random variables</a></li>
<li class="chapter" data-level="5.3" data-path="rvs.html"><a href="rvs.html#expectation"><i class="fa fa-check"></i><b>5.3</b> Expectation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="rvs.html"><a href="rvs.html#expectation-of-a-discrete-random-variable"><i class="fa fa-check"></i><b>5.3.1</b> Expectation of a discrete random variable</a></li>
<li class="chapter" data-level="5.3.2" data-path="rvs.html"><a href="rvs.html#expectation-of-a-continuous-random-variable"><i class="fa fa-check"></i><b>5.3.2</b> Expectation of a continuous random variable</a></li>
<li class="chapter" data-level="5.3.3" data-path="rvs.html"><a href="rvs.html#properties-of-mathrmex"><i class="fa fa-check"></i><b>5.3.3</b> Properties of <span class="math inline">\(\mathrm{E}(X)\)</span></a></li>
<li class="chapter" data-level="5.3.4" data-path="rvs.html"><a href="rvs.html#EgX"><i class="fa fa-check"></i><b>5.3.4</b> The expectation of <span class="math inline">\(g(X)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="rvs.html"><a href="rvs.html#variance"><i class="fa fa-check"></i><b>5.4</b> Variance</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="rvs.html"><a href="rvs.html#variance-of-a-discrete-random-variable"><i class="fa fa-check"></i><b>5.4.1</b> Variance of a discrete random variable</a></li>
<li class="chapter" data-level="5.4.2" data-path="rvs.html"><a href="rvs.html#variance-of-a-continuous-random-variable"><i class="fa fa-check"></i><b>5.4.2</b> Variance of a continuous random variable</a></li>
<li class="chapter" data-level="5.4.3" data-path="rvs.html"><a href="rvs.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>5.4.3</b> Variance and standard deviation</a></li>
<li class="chapter" data-level="5.4.4" data-path="rvs.html"><a href="rvs.html#properties-of-mathrmvarx"><i class="fa fa-check"></i><b>5.4.4</b> Properties of <span class="math inline">\(\mathrm{var}(X)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rvs.html"><a href="rvs.html#locations"><i class="fa fa-check"></i><b>5.5</b> Other measures of location</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="rvs.html"><a href="rvs.html#the-median-of-a-random-variable"><i class="fa fa-check"></i><b>5.5.1</b> The median of a random variable</a></li>
<li class="chapter" data-level="5.5.2" data-path="rvs.html"><a href="rvs.html#the-mode-of-a-random-variable"><i class="fa fa-check"></i><b>5.5.2</b> The mode of a random variable</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="rvs.html"><a href="rvs.html#quantiles"><i class="fa fa-check"></i><b>5.6</b> Quantiles</a></li>
<li class="chapter" data-level="5.7" data-path="rvs.html"><a href="rvs.html#measures-of-shape"><i class="fa fa-check"></i><b>5.7</b> Measures of shape</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>6</b> Simple distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="simple.html"><a href="simple.html#australian-births-data"><i class="fa fa-check"></i><b>6.1</b> Australian births data</a></li>
<li class="chapter" data-level="6.2" data-path="simple.html"><a href="simple.html#the-bernoulli-distribution"><i class="fa fa-check"></i><b>6.2</b> The Bernoulli distribution</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="simple.html"><a href="simple.html#summary-of-the-bernoullip-distribution"><i class="fa fa-check"></i><b>6.2.1</b> Summary of the Bernoulli(<span class="math inline">\(p\)</span>) distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="simple.html"><a href="simple.html#binomial"><i class="fa fa-check"></i><b>6.3</b> The binomial distribution</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="simple.html"><a href="simple.html#binominf"><i class="fa fa-check"></i><b>6.3.1</b> A brief look at statistical inference about <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="6.3.2" data-path="simple.html"><a href="simple.html#summary-of-the-binomialnp-distribution"><i class="fa fa-check"></i><b>6.3.2</b> Summary of the binomial(<span class="math inline">\(n,p\)</span>) distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="simple.html"><a href="simple.html#the-geometric-distribution"><i class="fa fa-check"></i><b>6.4</b> The geometric distribution</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="simple.html"><a href="simple.html#summary-of-the-geometricp-distribution"><i class="fa fa-check"></i><b>6.4.1</b> Summary of the geometric(<span class="math inline">\(p\)</span>) distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="simple.html"><a href="simple.html#Poisson"><i class="fa fa-check"></i><b>6.5</b> The Poisson distribution</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="simple.html"><a href="simple.html#summary-of-the-poissonmu-distribution"><i class="fa fa-check"></i><b>6.5.1</b> Summary of the Poisson(<span class="math inline">\(\mu\)</span>) distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="simple.html"><a href="simple.html#summary-of-these-discrete-distributions"><i class="fa fa-check"></i><b>6.6</b> Summary of these discrete distributions</a></li>
<li class="chapter" data-level="6.7" data-path="simple.html"><a href="simple.html#uniform"><i class="fa fa-check"></i><b>6.7</b> The uniform distribution</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="simple.html"><a href="simple.html#summary-of-the-uniformab-distribution"><i class="fa fa-check"></i><b>6.7.1</b> Summary of the uniform(<span class="math inline">\(a,b\)</span>) distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="simple.html"><a href="simple.html#exponential"><i class="fa fa-check"></i><b>6.8</b> The exponential distribution</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="simple.html"><a href="simple.html#summary-of-the-exponentiallambda-distribution"><i class="fa fa-check"></i><b>6.8.1</b> Summary of the exponential(<span class="math inline">\(\lambda\)</span>) distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="simple.html"><a href="simple.html#normal"><i class="fa fa-check"></i><b>6.9</b> The normal distribution</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="simple.html"><a href="simple.html#summary-of-the-mboxnmusigma2-distribution"><i class="fa fa-check"></i><b>6.9.1</b> Summary of the <span class="math inline">\(\mbox{N}(\mu,\sigma^2)\)</span> distribution</a></li>
<li class="chapter" data-level="6.9.2" data-path="simple.html"><a href="simple.html#the-standard-normal-disribution"><i class="fa fa-check"></i><b>6.9.2</b> The standard normal disribution</a></li>
<li class="chapter" data-level="6.9.3" data-path="simple.html"><a href="simple.html#evaluating-the-normal-c.d.f.-and-quantiles"><i class="fa fa-check"></i><b>6.9.3</b> Evaluating the normal c.d.f. and quantiles</a></li>
<li class="chapter" data-level="6.9.4" data-path="simple.html"><a href="simple.html#interpretation-of-sigma"><i class="fa fa-check"></i><b>6.9.4</b> Interpretation of <span class="math inline">\(\sigma\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="simple.html"><a href="simple.html#summary-of-these-continuous-distributions"><i class="fa fa-check"></i><b>6.10</b> Summary of these continuous distributions</a></li>
<li class="chapter" data-level="6.11" data-path="simple.html"><a href="simple.html#qq"><i class="fa fa-check"></i><b>6.11</b> QQ plots</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="simple.html"><a href="simple.html#normal-qq-plots"><i class="fa fa-check"></i><b>6.11.1</b> Normal QQ plots</a></li>
<li class="chapter" data-level="6.11.2" data-path="simple.html"><a href="simple.html#uniform-qq-plots"><i class="fa fa-check"></i><b>6.11.2</b> Uniform QQ plots</a></li>
<li class="chapter" data-level="6.11.3" data-path="simple.html"><a href="simple.html#exponential-qq-plots"><i class="fa fa-check"></i><b>6.11.3</b> Exponential QQ plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>7</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="7.1" data-path="inference.html"><a href="inference.html#the-story-so-far"><i class="fa fa-check"></i><b>7.1</b> The story so far</a></li>
<li class="chapter" data-level="7.2" data-path="inference.html"><a href="inference.html#sample-and-populations"><i class="fa fa-check"></i><b>7.2</b> Sample and populations</a></li>
<li class="chapter" data-level="7.3" data-path="inference.html"><a href="inference.html#probmodels"><i class="fa fa-check"></i><b>7.3</b> Probability models</a></li>
<li class="chapter" data-level="7.4" data-path="inference.html"><a href="inference.html#fitting-models"><i class="fa fa-check"></i><b>7.4</b> Fitting models</a></li>
<li class="chapter" data-level="7.5" data-path="inference.html"><a href="inference.html#uncertainty-in-estimation"><i class="fa fa-check"></i><b>7.5</b> Uncertainty in estimation</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="inference.html"><a href="inference.html#simulation-coin-tossing-example"><i class="fa fa-check"></i><b>7.5.1</b> Simulation: coin-tossing example</a></li>
<li class="chapter" data-level="7.5.2" data-path="inference.html"><a href="inference.html#simnorm"><i class="fa fa-check"></i><b>7.5.2</b> Simulation: estimating the parameters of a normal distribution</a></li>
<li class="chapter" data-level="7.5.3" data-path="inference.html"><a href="inference.html#simexp"><i class="fa fa-check"></i><b>7.5.3</b> Simulation: estimating the parameters of an exponential distribution</a></li>
<li class="chapter" data-level="7.5.4" data-path="inference.html"><a href="inference.html#central-limit-theorem-clt"><i class="fa fa-check"></i><b>7.5.4</b> Central Limit Theorem (CLT)</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="inference.html"><a href="inference.html#good"><i class="fa fa-check"></i><b>7.6</b> Properties of estimators</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="inference.html"><a href="inference.html#bias"><i class="fa fa-check"></i><b>7.6.1</b> Bias</a></li>
<li class="chapter" data-level="7.6.2" data-path="inference.html"><a href="inference.html#varianceofestimator"><i class="fa fa-check"></i><b>7.6.2</b> Variance</a></li>
<li class="chapter" data-level="7.6.3" data-path="inference.html"><a href="inference.html#mean-squared-error-mse"><i class="fa fa-check"></i><b>7.6.3</b> Mean squared error (MSE)</a></li>
<li class="chapter" data-level="7.6.4" data-path="inference.html"><a href="inference.html#standard-error"><i class="fa fa-check"></i><b>7.6.4</b> Standard error</a></li>
<li class="chapter" data-level="7.6.5" data-path="inference.html"><a href="inference.html#consistency"><i class="fa fa-check"></i><b>7.6.5</b> Consistency</a></li>
<li class="chapter" data-level="7.6.6" data-path="inference.html"><a href="inference.html#normal-example"><i class="fa fa-check"></i><b>7.6.6</b> Normal example</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="inference.html"><a href="inference.html#assessing-goodness-of-fit"><i class="fa fa-check"></i><b>7.7</b> Assessing goodness-of-fit</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="inference.html"><a href="inference.html#residuals"><i class="fa fa-check"></i><b>7.7.1</b> Residuals</a></li>
<li class="chapter" data-level="7.7.2" data-path="inference.html"><a href="inference.html#standardised-residuals"><i class="fa fa-check"></i><b>7.7.2</b> Standardised residuals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="contingency.html"><a href="contingency.html"><i class="fa fa-check"></i><b>8</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="contingency.html"><a href="contingency.html#way2"><i class="fa fa-check"></i><b>8.1</b> 2-way contingency tables</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="contingency.html"><a href="contingency.html#indep"><i class="fa fa-check"></i><b>8.1.1</b> Independence</a></li>
<li class="chapter" data-level="8.1.2" data-path="contingency.html"><a href="contingency.html#compprob"><i class="fa fa-check"></i><b>8.1.2</b> Comparing probabilities</a></li>
<li class="chapter" data-level="8.1.3" data-path="contingency.html"><a href="contingency.html#measures"><i class="fa fa-check"></i><b>8.1.3</b> Measures of association</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="contingency.html"><a href="contingency.html#way3"><i class="fa fa-check"></i><b>8.2</b> 3-way contingency tables</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="contingency.html"><a href="contingency.html#mutual-independence"><i class="fa fa-check"></i><b>8.2.1</b> Mutual independence</a></li>
<li class="chapter" data-level="8.2.2" data-path="contingency.html"><a href="contingency.html#marginal-independence"><i class="fa fa-check"></i><b>8.2.2</b> Marginal independence</a></li>
<li class="chapter" data-level="8.2.3" data-path="contingency.html"><a href="contingency.html#conditional-independence"><i class="fa fa-check"></i><b>8.2.3</b> Conditional independence</a></li>
<li class="chapter" data-level="8.2.4" data-path="contingency.html"><a href="contingency.html#confounding-variables"><i class="fa fa-check"></i><b>8.2.4</b> Confounding variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linreg.html"><a href="linreg.html"><i class="fa fa-check"></i><b>9</b> Linear regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="linreg.html"><a href="linreg.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="linreg.html"><a href="linreg.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>9.1.1</b> Simple linear regression model</a></li>
<li class="chapter" data-level="9.1.2" data-path="linreg.html"><a href="linreg.html#least-squares-estimation-of-alpha-and-beta"><i class="fa fa-check"></i><b>9.1.2</b> Least squares estimation of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span></a></li>
<li class="chapter" data-level="9.1.3" data-path="linreg.html"><a href="linreg.html#least-squares-fitting-to-hubbles-data"><i class="fa fa-check"></i><b>9.1.3</b> Least squares fitting to Hubble’s data</a></li>
<li class="chapter" data-level="9.1.4" data-path="linreg.html"><a href="linreg.html#normal-linear-regression-model"><i class="fa fa-check"></i><b>9.1.4</b> Normal linear regression model</a></li>
<li class="chapter" data-level="9.1.5" data-path="linreg.html"><a href="linreg.html#lmsummary"><i class="fa fa-check"></i><b>9.1.5</b> Summary of the assumptions of a (normal) linear regression model</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="linreg.html"><a href="linreg.html#looking"><i class="fa fa-check"></i><b>9.2</b> Looking at scatter plots</a></li>
<li class="chapter" data-level="9.3" data-path="linreg.html"><a href="linreg.html#model-checking"><i class="fa fa-check"></i><b>9.3</b> Model checking</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="linreg.html"><a href="linreg.html#departures-from-assumptions"><i class="fa fa-check"></i><b>9.3.1</b> Departures from assumptions</a></li>
<li class="chapter" data-level="9.3.2" data-path="linreg.html"><a href="linreg.html#outliers"><i class="fa fa-check"></i><b>9.3.2</b> Outliers and influential observations</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="linreg.html"><a href="linreg.html#linregtrans"><i class="fa fa-check"></i><b>9.4</b> Use of transformations</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="linreg.html"><a href="linreg.html#interpretation-after-transformation"><i class="fa fa-check"></i><b>9.4.1</b> Interpretation after transformation</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="linreg.html"><a href="linreg.html#over-fitting"><i class="fa fa-check"></i><b>9.5</b> Over-fitting</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="correlationchapter.html"><a href="correlationchapter.html"><i class="fa fa-check"></i><b>10</b> Correlation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="correlationchapter.html"><a href="correlationchapter.html#correlation-a-measure-of-linear-association"><i class="fa fa-check"></i><b>10.1</b> Correlation: a measure of linear association</a></li>
<li class="chapter" data-level="10.2" data-path="correlationchapter.html"><a href="correlationchapter.html#covariance-and-correlation"><i class="fa fa-check"></i><b>10.2</b> Covariance and correlation</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="correlationchapter.html"><a href="correlationchapter.html#estimation"><i class="fa fa-check"></i><b>10.2.1</b> Estimation</a></li>
<li class="chapter" data-level="10.2.2" data-path="correlationchapter.html"><a href="correlationchapter.html#links-between-regression-and-correlation"><i class="fa fa-check"></i><b>10.2.2</b> Links between regression and correlation</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="correlationchapter.html"><a href="correlationchapter.html#use-and-misuse-of-correlation"><i class="fa fa-check"></i><b>10.3</b> Use and misuse of correlation</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="correlationchapter.html"><a href="correlationchapter.html#do-not-use-correlation-for-regression-sampling-schemes"><i class="fa fa-check"></i><b>10.3.1</b> Do not use correlation for regression sampling schemes</a></li>
<li class="chapter" data-level="10.3.2" data-path="correlationchapter.html"><a href="correlationchapter.html#correxamples"><i class="fa fa-check"></i><b>10.3.2</b> Examples of correlations of different strengths</a></li>
<li class="chapter" data-level="10.3.3" data-path="correlationchapter.html"><a href="correlationchapter.html#beware-missing-data-codes"><i class="fa fa-check"></i><b>10.3.3</b> Beware missing data codes</a></li>
<li class="chapter" data-level="10.3.4" data-path="correlationchapter.html"><a href="correlationchapter.html#more-guessing-sample-correlations"><i class="fa fa-check"></i><b>10.3.4</b> More guessing sample correlations</a></li>
<li class="chapter" data-level="10.3.5" data-path="correlationchapter.html"><a href="correlationchapter.html#summary"><i class="fa fa-check"></i><b>10.3.5</b> Summary</a></li>
<li class="chapter" data-level="10.3.6" data-path="correlationchapter.html"><a href="correlationchapter.html#anscombes-datasets"><i class="fa fa-check"></i><b>10.3.6</b> Anscombe’s datasets</a></li>
<li class="chapter" data-level="10.3.7" data-path="correlationchapter.html"><a href="correlationchapter.html#we-must-interpret-correlation-with-care."><i class="fa fa-check"></i><b>10.3.7</b> We must interpret correlation with care.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="a-general-strategy-for-statistical-modelling.html"><a href="a-general-strategy-for-statistical-modelling.html"><i class="fa fa-check"></i><b>11</b> A general strategy for statistical modelling</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT0002 Introduction to Probability and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="rvs" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Random variables<a href="rvs.html#rvs" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Example</strong>. We return to the space shuttle example.</p>
<p>Consider what happens to the O-rings on a particular test flight, at a particular temperature. A given O-ring either is damaged (shows signs of thermal distress) or it is not damaged. Let <span class="math inline">\(D\)</span> denote the event that an O-ring is damaged and <span class="math inline">\(\bar{D}\)</span> the event that it is not damaged. If we consider all 6 O-rings, there are many possible outcomes in the sample space, <span class="math inline">\(2^6=64\)</span>, in fact:
<span class="math display">\[ S= \{DDDDDD\}, \{DDDDD\bar{D}\}, \ldots, \{D\bar{D}\bar{D}\bar{D}\bar{D}\bar{D}\},
\{\bar{D}\bar{D}\bar{D}\bar{D}\bar{D}\bar{D}\}. \]</span>
Suppose that we are not interested in which particular O-rings were damaged, just the total number <span class="math inline">\(N\)</span> of damaged O-rings. The possible values for <span class="math inline">\(N\)</span> are 0,1,2,3,4,5,6.</p>
<p>Each outcome in <span class="math inline">\(S\)</span> gives a value for <span class="math inline">\(N\)</span> in {0,1,2,3,4,5,6}:</p>
<p><span class="math inline">\(\{DDDDDD\}\)</span> gives <span class="math inline">\(N=6\)</span>,</p>
<p><span class="math inline">\(\{DDDDD\bar{D}\}\)</span> gives <span class="math inline">\(N=5\)</span>,</p>
<p><span class="math inline">\(\{DDDD\bar{D}D\}\)</span> gives <span class="math inline">\(N=5\)</span>,</p>
<p><span class="math inline">\(\vdots\)</span></p>
<p><span class="math inline">\(\{\bar{D}\bar{D}\bar{D}\bar{D}\bar{D}\bar{D}\}\)</span> gives <span class="math inline">\(N=0\)</span>.</p>
<p>By defining <span class="math inline">\(N\)</span> to be the total number of damaged O-rings, we have moved from considering outcomes to considering a variable with a numerical value. <span class="math inline">\(N\)</span> is a real-valued function on the sample space <span class="math inline">\(S\)</span>, that is, <span class="math inline">\(N\)</span> maps each outcome in <span class="math inline">\(S\)</span> to a real number. <span class="math inline">\(N\)</span> is a rule that assigns a real number to every outcome <span class="math inline">\(s\)</span> in <span class="math inline">\(S\)</span>. Since the outcomes in <span class="math inline">\(S\)</span> are random the variable <span class="math inline">\(N\)</span> is also random, and we can assign probabilities to its possible values, that is, <span class="math inline">\(P(N=0), P(N=1)\)</span> and so on.</p>
<p><span class="math inline">\(N\)</span> is a <strong>random variable</strong>. In fact, if we assume that O-rings are damaged independently of each other and each O-ring has the same probability <span class="math inline">\(p\)</span> of being damaged, <span class="math inline">\(N\)</span> is a random variable with a special name. It is a binomial random variable with parameters 6 and <span class="math inline">\(p\)</span>. We will consider binomial random variables in more detail in Section <a href="simple.html#binomial">6.3</a>.</p>
<p><strong>Notation</strong>. We denote random variables by upper case letters, for example, <span class="math inline">\(N, X, Y, Z\)</span>. Once we have observed the value of a random variable it is no longer random: it is equal to a particular numeric value. To make this clear we denote sample values of r.v.s. by lower case letters, for example, <span class="math inline">\(n, x, y, z\)</span> and write <span class="math inline">\(N=n, X=x\)</span> and so on. Thus, <span class="math inline">\(P(X=x)\)</span> is the probability that the random variable <span class="math inline">\(X\)</span> has the value <span class="math inline">\(x\)</span>.</p>
<div id="discrete" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Discrete random variables<a href="rvs.html#discrete" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Definition</strong>. A discrete random variable is a random variable that can take only a finite, or countably infinite, number of values.</p>
<p>An example of a countably infinite set of values is {0,1,2,3, …}. The random variable <span class="math inline">\(N\)</span> in the space shuttle example takes a finite number of values: 0,1,2,3,4,5,6. Therefore <span class="math inline">\(N\)</span> is a discrete random variable.</p>
<p><strong>Definition</strong>. Let <span class="math inline">\(X\)</span> be a discrete random variable. The <strong>probability mass function (p.m.f.)</strong> <span class="math inline">\(p_X(x)\)</span>, or simply <span class="math inline">\(p(x)\)</span>, of <span class="math inline">\(X\)</span> is
<span class="math display">\[ p_X(x) = P(X=x), \qquad \mbox{for $x$ in the support of $X$}.  \]</span></p>
<p>The p.m.f. of <span class="math inline">\(X\)</span> tells us the probability with which <span class="math inline">\(X\)</span> takes any particular value <span class="math inline">\(x\)</span>. The <strong>support</strong> of <span class="math inline">\(X\)</span> is the set of values that it is possible for <span class="math inline">\(X\)</span> to take. It is very important to write this down every time you write down a p.m.f.. A discrete random variable is completely specified by its probability mass function.</p>
<p><strong>Properties of p.m.f.s</strong></p>
<p>Let <span class="math inline">\(X\)</span> take values <span class="math inline">\(x_1, x_2,\ldots.\)</span> Then</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(p_X(x_i) \geq 0\)</span>, for all <span class="math inline">\(i\)</span>,</li>
<li><span class="math inline">\(\displaystyle\sum_i p_X(x_i) = 1\)</span>.</li>
</ol>
<p>Note: 1. is true because the <span class="math inline">\(p_X(x_i)\)</span>s are probabilities; 2. is true because summing over the <span class="math inline">\(x_i\)</span>s is equivalent to summing over the sample space of outcomes.</p>
<p><strong>Definition</strong>. The cumulative distribution function (c.d.f.) of a random variable <span class="math inline">\(X\)</span> is
<span class="math display">\[ F_X(x) = P(X \leq x), \qquad \mbox{for} -\infty &lt; x &lt; \infty. \]</span></p>
<p><strong>Relationship between the c.d.f. and p.m.f. of a discrete random variable</strong>. For a discrete random variable:
<span class="math display">\[ F_X(x) = P(X \leq x) = \sum_{x_i \leq x} P(X = x_i). \]</span>
Therefore, assuming for the moment that the random variable takes only integer values,
<span class="math display">\[ P(X=x) = P(X \leq x) - P(X \leq x-1) = F_X(x) - F_X(x-1) \]</span>
for any integer <span class="math inline">\(x\)</span></p>
</div>
<div id="continuous" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Continuous random variables<a href="rvs.html#continuous" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Example</strong>. We return to the Oxford birth times example.</p>
<p>The top plot in Figure <a href="rvs.html#fig:oxcontvar">5.1</a> shows a histogram of the 95 birth times. The variable of interest in this example is a time. Time is a continuous variable: in principle, the times in this dataset could take any positive real value, uncountably many values. In practice, these times have been recorded discretely, in units of 1/10 of an hour or 1/4 of an hour.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:oxcontvar"></span>
<img src="images/ox_cont_var.png" alt="Top: histogram of the Oxford birth durations. Second from top: histogram of 1,000 values simulated from a distribution fitted to the data. Second from bottom: similarly for 10,000 simulated values. Bottom: p.d.f. of the distribution fitted to the Oxford birth times data." width="75%" />
<p class="caption">
Figure 5.1: Top: histogram of the Oxford birth durations. Second from top: histogram of 1,000 values simulated from a distribution fitted to the data. Second from bottom: similarly for 10,000 simulated values. Bottom: p.d.f. of the distribution fitted to the Oxford birth times data.
</p>
</div>
<p>Suppose that we continue to collect data on birth duration from this hospital, and, as new observations arrive, we add them to the top histogram in Figure <a href="rvs.html#fig:oxcontvar">5.1</a>. We imagine that the times are recorded continuously. As the number of observations <span class="math inline">\(n\)</span> increases we decrease the bin width of the histogram. As <span class="math inline">\(n\)</span> increases to infinity the bin width shrinks to zero and the histogram tends to a smooth continuous curve.</p>
<p>This is shown in the bottom 3 plots in Figure <a href="rvs.html#fig:oxcontvar">5.1</a>. The extra data are not real. They are data I have simulated, using a computer, to have a distribution with a similar shape to the histogram of the real data.</p>
<p>Let <span class="math inline">\(T\)</span> denote the time, in hours, that a woman arriving at the hospital takes to give birth. The smooth continuous curve at the bottom of Figure <a href="rvs.html#fig:oxcontvar">5.1</a> is called the <strong>probability density function (p.d.f.)</strong> <span class="math inline">\(f_T(t)\)</span> of the random variable <span class="math inline">\(T\)</span>. Since the total area of the rectangles in a histogram is equal to 1, the area <span class="math inline">\(\int_{-\infty}^{\infty} f_T(t) \, \mathrm{d}t\)</span> under the p.d.f. <span class="math inline">\(f_T(t)\)</span> is equal to 1.</p>
<p><strong>Definition</strong>. A <strong>probability density function (p.d.f.)</strong> is a function <span class="math inline">\(f_{X}(x)\)</span>, or simply <span class="math inline">\(f(x)\)</span>, such that</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(f_X(x) \geq 0\)</span>, for <span class="math inline">\(-\infty &lt; x &lt; \infty\)</span>;</li>
<li><span class="math inline">\(\displaystyle\int_{-\infty}^{\infty} f_X(x) \, \mathrm{d}x = 1\)</span>.</li>
</ol>
<p>Therefore, p.d.f.s are always non-negative and integrate to 1. The support of a continuous random variable is the set of values for which the p.d.f. is positive. Suppose that we wish to find <span class="math inline">\(P(4 &lt; T \leq 12)\)</span>. To find the proportion of times between 4 and 12 using a histogram, we sum the areas of all bins between 4 and 12, that is, we find the area shaded in the histogram in Figure <a href="rvs.html#fig:oxshady">5.2</a>. To do this using the p.d.f. we do effectively the same thing: we find the area under the p.d.f. <span class="math inline">\(f_T(t)\)</span> between 4 and 12. Since <span class="math inline">\(f_T(t)\)</span> is a smooth continuous curve, (that is, the bin widths are zero) we integrate <span class="math inline">\(f_T(t)\)</span> between 4 and 12.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:oxshady"></span>
<img src="images/ox_shady.png" alt="Top: histogram of the Oxford birth durations. Bottom: p.d.f. of the distribution fitted to the Oxford birth duration data." width="75%" />
<p class="caption">
Figure 5.2: Top: histogram of the Oxford birth durations. Bottom: p.d.f. of the distribution fitted to the Oxford birth duration data.
</p>
</div>
<p>Therefore
<span class="math display">\[ P(4 &lt; T \leq 12) = \displaystyle\int_4^{12} f_T(t) \,\mathrm{d}t = F_T(12)-F_T(4). \]</span></p>
<p>More generally,
<span class="math display">\[ P(a &lt; T \leq b) = \displaystyle\int_a^b f_T(t) \,\mathrm{d}t = F_T(b)-F_T(a). \]</span></p>
<p><strong>Definition</strong>. A random variable <span class="math inline">\(X\)</span> is a <strong>continuous random variable</strong> if there exists a p.d.f. <span class="math inline">\(f_X(x)\)</span> such that
<span class="math display">\[
P(a &lt; X \leq b) = \int_{a}^{b} f_X(x) \,\mathrm{d}x,
\]</span>
for all <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that <span class="math inline">\(a &lt; b\)</span>.</p>
<p>Figure <a href="rvs.html#fig:pdfshady">5.3</a> illustrates the properties of a p.d.f..</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pdfshady"></span>
<img src="images/pdf_shady.png" alt="Properties of a p.d.f.. The areas that correspond to the probability that a random variable takes a value in a given interval are shaded." width="75%" />
<p class="caption">
Figure 5.3: Properties of a p.d.f.. The areas that correspond to the probability that a random variable takes a value in a given interval are shaded.
</p>
</div>
<p>Notes</p>
<ul>
<li>It is very important to appreciate that <span class="math inline">\(f_X(x)\)</span> is <strong>not</strong> a probability: it does <strong>not</strong> give <span class="math inline">\(P(X=x)\)</span>. In fact <span class="math inline">\(P(X=x)=0\)</span>: the probability that a continuous random variable <span class="math inline">\(X\)</span> takes the value <span class="math inline">\(x\)</span> is zero.</li>
<li>Indeed, it is possible for a p.d.f. to be greater than 1. Consider a continuous random variable <span class="math inline">\(X\)</span> with p.d.f.
<span class="math display">\[ f_X(x) = \left\{ \begin{array}{ll} 2\,(1-x) &amp; \,0 \leq x \leq 1, \\ 0 &amp; \,\mbox{otherwise}.\end{array}\right. \]</span>
For this random variable <span class="math inline">\(f_X(x)&gt;1\)</span> for any <span class="math inline">\(x \in [0, 1/2)\)</span> .</li>
<li>Since, for any <span class="math inline">\(x \in \mathbb{R}\)</span>, <span class="math inline">\(P(X=x)=0\)</span>
<span class="math display">\[ P(a &lt; X \leq b) = P(a \leq X \leq b) = P(a \leq X &lt; b) = P(a &lt; X &lt; b). \]</span></li>
<li><span class="math inline">\(f_X(x)\)</span> is a probability <strong>density</strong>. The probability that <span class="math inline">\(X\)</span> lies in a very small interval of length <span class="math inline">\(\delta\)</span> near <span class="math inline">\(x\)</span> is approximately <span class="math inline">\(f_X(x) \delta\)</span>. For the p.d.f. at the bottom of Figure <a href="rvs.html#fig:oxcontvar">5.1</a>, <span class="math inline">\(f_T(6) &gt; f_T(12)\)</span>, indicating that a randomly chosen woman is more likely to spend approximately 6 hours giving birth than approximately
12 hours.</li>
</ul>
<p><strong>Relationship between the c.d.f. and p.d.f. of a continuous random variable</strong>. For a continuous random variable
<span class="math display">\[ F_X(x) = P(X \leq x) = \int_{-\infty}^x f_X(u) \,\mathrm{d}u. \]</span>
Therefore,
<span class="math display">\[ f_X(x) = \frac{\mathrm{d}}{\mathrm{d}x} F_X(x). \]</span></p>
</div>
<div id="expectation" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Expectation<a href="rvs.html#expectation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The expectation of a random variable is a measure of the location of its distribution.</p>
<div id="expectation-of-a-discrete-random-variable" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Expectation of a discrete random variable<a href="rvs.html#expectation-of-a-discrete-random-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Example</strong>. We return to the space shuttle example.</p>
<p>Again we consider test flights conducted at a particular temperature, say 53<span class="math inline">\(^\circ\)</span>F. Suppose that NASA are able to conduct a very large number <span class="math inline">\(n\)</span> of test flights at 53<span class="math inline">\(^\circ\)</span>F, producing a sample <span class="math inline">\(x_1,\ldots,x_n\)</span> of numbers of damaged O-rings.</p>
<p>Let <span class="math inline">\(n(x)\)</span> be the number of test flights on which <span class="math inline">\(x\)</span> of the 6 O-rings were damaged. We can write the sample mean <span class="math inline">\(\bar{x}\)</span> of <span class="math inline">\(x_1,\ldots,x_n\)</span> as
<span class="math display">\[\begin{eqnarray*}
\bar{x} &amp;=&amp; \frac{0 \times n(0) + 1 \times n(1) + \cdots + 6 \times n(6)}{n}, \\
&amp;=&amp; \sum_{x=0}^6 x\,\frac{n(x)}{n}.
\end{eqnarray*}\]</span>
As the sample size <span class="math inline">\(n\)</span> increases to infinity, the sample proportion <span class="math inline">\(n(x)/n\)</span> tends to <span class="math inline">\(P(X=x)\)</span>, for <span class="math inline">\(x=0,1,\ldots,6\)</span>. Therefore, in the limit as <span class="math inline">\(n \rightarrow \infty\)</span>, <span class="math inline">\(\bar{x}\)</span> tends to
<span class="math display" id="eq:shuttlemean">\[\begin{eqnarray}
\sum_{x=0}^6 x\,P(X=x).
\tag{5.1}
\end{eqnarray}\]</span>
This is known as the mean of the probability distribution of <span class="math inline">\(X\)</span>. It is a measure of the location of the distribution.</p>
<p>The quantity in equation <a href="rvs.html#eq:shuttlemean">(5.1)</a> is the value of the sample mean <span class="math inline">\(\bar{x}\)</span> that we would expect to get from a very large sample. Therefore it is often called the <strong>expectation</strong> or <strong>expected value</strong> of the random variable <span class="math inline">\(X\)</span> and it is denoted <span class="math inline">\(\mathrm{E}(X)\)</span>.</p>
<p><strong>Definition</strong>. The <strong>expectation</strong> (or <strong>expected value</strong> or <strong>mean</strong>) <span class="math inline">\(\mathrm{E}(X)\)</span> of a discrete random variable <span class="math inline">\(X\)</span> is given by
<span class="math display" id="eq:discmean">\[\begin{eqnarray}
\mathrm{E}(X) &amp;=&amp; \sum_x x\,P(X=x).
\tag{5.2}
\end{eqnarray}\]</span>
This is a weighted average of the values that <span class="math inline">\(X\)</span> can take, each value being weighted by <span class="math inline">\(P(X=x)\)</span>.</p>
<p>Note:</p>
<ul>
<li>We often write <span class="math inline">\(\mu\)</span> or <span class="math inline">\(\mu_X\)</span> for <span class="math inline">\(\mathrm{E}(X)\)</span>.</li>
<li>Units: the units of <span class="math inline">\(\mathrm{E}(X)\)</span> are the same as those of <span class="math inline">\(X\)</span>. For example, if <span class="math inline">\(X\)</span> is measured in hours then <span class="math inline">\(\mathrm{E}(X)\)</span> is measured in hours.</li>
<li><span class="math inline">\(\mathrm{E}(X)\)</span> exists only if <span class="math inline">\(\sum_x |x|\,P(X=x) &lt; \infty\)</span>. If the number of values <span class="math inline">\(X\)</span> can take is finite then <span class="math inline">\(\mathrm{E}(X)\)</span> will always exist.</li>
</ul>
</div>
<div id="expectation-of-a-continuous-random-variable" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Expectation of a continuous random variable<a href="rvs.html#expectation-of-a-continuous-random-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can define the expectation of a continuous random variable in a similar way to a discrete random variable, replacing summation with integration.</p>
<p><strong>Definition</strong>.
The expectation <span class="math inline">\(\mathrm{E}(X)\)</span> of a continuous random variable <span class="math inline">\(X\)</span> is given by
<span class="math display" id="eq:contmean">\[\begin{eqnarray}
\mathrm{E}(X) = \int_{-\infty}^{\infty} x\,f_X(x) \,\mathrm{d}x.
\tag{5.3}
\end{eqnarray}\]</span>
Note:</p>
<ul>
<li>Like the discrete case, this is a weighted average of the values that <span class="math inline">\(X\)</span> can take, but now each value is weighted by the
p.d.f. <span class="math inline">\(f_X(x)\)</span>.</li>
<li>The range of integration in equation <a href="rvs.html#eq:contmean">(5.3)</a> is over the whole real line but, in practice, integration will be over the range of possible values of <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\(\mathrm{E}(X)\)</span> exists only if <span class="math inline">\(\int_{-\infty}^{\infty} |x|\,f_X(x) \,\mathrm{d}x &lt; \infty\)</span>.</li>
</ul>
</div>
<div id="properties-of-mathrmex" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Properties of <span class="math inline">\(\mathrm{E}(X)\)</span><a href="rvs.html#properties-of-mathrmex" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are constants then
<span class="math display">\[ \mathrm{E}(a\,X+b) = a\,\mathrm{E}(X)+b. \]</span>
This makes sense. If we multiply all observations by <span class="math inline">\(a\)</span> their mean will also be multiplied by <span class="math inline">\(a\)</span>. If we add <span class="math inline">\(b\)</span> to all observations their mean will be increased by <span class="math inline">\(b\)</span>, that is, the distribution of <span class="math inline">\(X\)</span> shifts up by <span class="math inline">\(b\)</span>.</p>
<ul>
<li>If <span class="math inline">\(X \geq 0\)</span> then <span class="math inline">\(\mathrm{E}(X) \geq 0\)</span>.</li>
<li>If <span class="math inline">\(X\)</span> is a constant <span class="math inline">\(c\)</span>, that is, <span class="math inline">\(P(X=c)=1\)</span> then <span class="math inline">\(\mathrm{E}(X)=c\)</span>.</li>
<li>It can be shown that
<span class="math display">\[ \mathrm{E}(X_1 + X_2 + \cdots + X_n) = \mathrm{E}(X_1) + \mathrm{E}(X_2) + \cdots + \mathrm{E}(X_n). \]</span></li>
</ul>
</div>
<div id="EgX" class="section level3 hasAnchor" number="5.3.4">
<h3><span class="header-section-number">5.3.4</span> The expectation of <span class="math inline">\(g(X)\)</span><a href="rvs.html#EgX" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that <span class="math inline">\(Y=g(X)\)</span> is a function of of <span class="math inline">\(X\)</span>, such as <span class="math inline">\(aX+b\)</span>, <span class="math inline">\(X^2\)</span> or <span class="math inline">\(\log X\)</span>. Then <span class="math inline">\(Y\)</span> is also a random variable. If we find the p.m.f (if <span class="math inline">\(Y\)</span> is discrete) or p.d.f. (if <span class="math inline">\(Y\)</span> is continuous) of <span class="math inline">\(Y\)</span> then we can find the expectation of <span class="math inline">\(Y\)</span> using equation <a href="rvs.html#eq:discmean">(5.2)</a> or <a href="rvs.html#eq:contmean">(5.3)</a> as appropriate. Alternatively, and often more easily, we can use</p>
<p><span class="math display" id="eq:expfn">\[\begin{equation}
\mathrm{E}(Y) = \mathrm{E}[g(X)] =
\begin{cases}
\displaystyle\sum_x g(x)\,P(X=x) &amp; \text{if } X \text{ is discrete}, \\
\int_{-\infty}^{\infty} g(x)\,f_X(x) \,\mathrm{d}x &amp; \text{if } X \text{ is continuous}.
\end{cases}
\tag{5.4}
\end{equation}\]</span></p>
<p>Note: for a non-linear function <span class="math inline">\(g(X)\)</span>, it is usually the case that
<span class="math display">\[ \mathrm{E}[g(X)] \neq g[\mathrm{E}(X)] \]</span>
although there are exceptions.</p>
</div>
</div>
<div id="variance" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Variance<a href="rvs.html#variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The variance of a random variable is a measure of the spread of its distribution.</p>
<div id="variance-of-a-discrete-random-variable" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Variance of a discrete random variable<a href="rvs.html#variance-of-a-discrete-random-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Example</strong>. We return the space shuttle example.</p>
<p>As before we let <span class="math inline">\(n(x)\)</span> be the number of test flights on which <span class="math inline">\(x\)</span> of the 6 O-rings were damaged. We saw in Section <a href="descriptive.html#meanstdev">2.3.2</a> that a measure of the spread of a sample <span class="math inline">\(x_1,\ldots,x_n\)</span> is the sample variance <span class="math inline">\(s_X^2\)</span> which, in this example, can be written as</p>
<p><span class="math display">\[\begin{eqnarray*}
s_X^2 &amp;=&amp; \frac{1}{n-1}\,\left\{
(0-\bar{x})^2\,n(0)+(1-\bar{x})^2\,n(1)+\cdots+(6-\bar{x})^2\,n(6) \right\},
\\
      &amp;=&amp; \sum_{x=0}^6 (x-\bar{x})^2\,\frac{n(x)}{n-1}.
\end{eqnarray*}\]</span>
As the sample size <span class="math inline">\(n\)</span> increases to infinity, <span class="math inline">\(\frac{n(x)}{n-1}\)</span> tends to <span class="math inline">\(P(X=x)\)</span>, for <span class="math inline">\(x=0,1,\ldots,6\)</span> and <span class="math inline">\(\bar{x}\)</span> tends to <span class="math inline">\(\mu\)</span>=<span class="math inline">\(\mathrm{E}(X)\)</span>.</p>
<p>Therefore, as <span class="math inline">\(n \rightarrow \infty\)</span>, <span class="math inline">\(s_X^2\)</span> tends to</p>
<p><span class="math display" id="eq:shuttlevar">\[\begin{equation}
\sum_{x=0}^6 (x-\mu)^2\,P(X=x).
\tag{5.5}
\end{equation}\]</span></p>
<p>This is known as the variance of the probability distribution of <span class="math inline">\(X\)</span>. It is a measure of the spread of the distribution. The quantity in equation <a href="rvs.html#eq:shuttlevar">(5.5)</a> is the value of the sample variance <span class="math inline">\(s_X^2\)</span> that we would expect to get from a very large sample.</p>
<p><strong>Definition</strong>. The variance <span class="math inline">\(\mathrm{var}(X)\)</span> of a discrete random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mathrm{E}(X)=\mu\)</span> is given by</p>
<p><span class="math display" id="eq:varidisc">\[\begin{equation}
\mathrm{var}(X) = \sum_x\,(x-\mu)^2\,P(X=x).
\tag{5.6}
\end{equation}\]</span></p>
<p>This is a weighted average of the squared differences between the values that <span class="math inline">\(X\)</span> can take and its mean <span class="math inline">\(\mu\)</span>, each value being weighted by <span class="math inline">\(P(X=x)\)</span>.</p>
<p>A variance can be infinite. If the number of values that <span class="math inline">\(X\)</span> can take is finite then <span class="math inline">\(\mathrm{var}(X)\)</span> will always be finite.</p>
</div>
<div id="variance-of-a-continuous-random-variable" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Variance of a continuous random variable<a href="rvs.html#variance-of-a-continuous-random-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can define the variance of a continuous random variable in a similar way to a discrete random variable, replacing summation with integration.</p>
<p><strong>Definition</strong>. The variance <span class="math inline">\(\mathrm{var}(X)\)</span> of a continuous random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mathrm{E}(X)=\mu\)</span> is given by</p>
<p><span class="math display" id="eq:varicont">\[\begin{equation}
\mathrm{var}(X) = \int_{-\infty}^{\infty} (x-\mu)^2 f_X(x) \,\mathrm{d}x.
\tag{5.7}
\end{equation}\]</span></p>
</div>
<div id="variance-and-standard-deviation" class="section level3 hasAnchor" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Variance and standard deviation<a href="rvs.html#variance-and-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Definition</strong>. Let <span class="math inline">\(X\)</span> be a random variable with <span class="math inline">\(\mathrm{E}(X)=\mu\)</span>. The variance <span class="math inline">\(\mathrm{var}(X)\)</span> is given by
<span class="math display">\[ \mathrm{var}(X) = \mathrm{E}\left[(X-\mu)^2\right]. \]</span>
This follows from equations <a href="rvs.html#eq:varidisc">(5.6)</a> and <a href="rvs.html#eq:varicont">(5.7)</a> and the expression in equation <a href="rvs.html#eq:expfn">(5.4)</a> for the expectation of a function <span class="math inline">\(g(X)\)</span> of a random variable <span class="math inline">\(X\)</span>.</p>
<p>There is an alternative way to calculate <span class="math inline">\(\mathrm{var}(X)\)</span>:
<span class="math display">\[ \mathrm{var}(X) = \mathrm{E}\left(X^2\right) - [\mathrm{E}(X)]^2. \]</span></p>
<p><strong>Exercise</strong>. Prove this.</p>
<p><strong>Definition</strong>. The standard deviation sd<span class="math inline">\((X)\)</span> of <span class="math inline">\(X\)</span> is given by sd(<span class="math inline">\(X\)</span>)=<span class="math inline">\(+\sqrt{\mathrm{var}(X)}\)</span>.</p>
<p>Notes on <span class="math inline">\(\mathrm{var}(X)\)</span> and sd(<span class="math inline">\(X\)</span>):</p>
<ul>
<li><span class="math inline">\(\mathrm{var}(X) \geq 0\)</span> and <span class="math inline">\(\mathrm{sd}(X) \geq 0\)</span>. Variances and standard deviations cannot be negative.<br />
</li>
<li>The units of <span class="math inline">\(\mathrm{var}(X)\)</span> are the square of those of <span class="math inline">\(X\)</span>. For example, if <span class="math inline">\(X\)</span> is measured in hours then <span class="math inline">\(\mathrm{var}(X)\)</span> is measured in hours<span class="math inline">\(^2\)</span> (and sd(<span class="math inline">\(X\)</span>) is measured in hours). The units of <span class="math inline">\(\mathrm{sd}(X)\)</span> are the same as those of <span class="math inline">\(X\)</span>.</li>
<li>We often write <span class="math inline">\(\sigma^2\)</span> or <span class="math inline">\(\sigma_X^2\)</span> for <span class="math inline">\(\mathrm{var}(X)\)</span> and
<span class="math inline">\(\sigma\)</span> or <span class="math inline">\(\sigma_X\)</span> for <span class="math inline">\(\mathrm{sd}(X)\)</span>.</li>
<li><span class="math inline">\(\mathrm{var}(X)\)</span> exists only if <span class="math inline">\(\mu\)</span> exists.</li>
</ul>
</div>
<div id="properties-of-mathrmvarx" class="section level3 hasAnchor" number="5.4.4">
<h3><span class="header-section-number">5.4.4</span> Properties of <span class="math inline">\(\mathrm{var}(X)\)</span><a href="rvs.html#properties-of-mathrmvarx" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>If <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are constants then
<span class="math display">\[ \mathrm{var}(a\,X+b) = a^2\,\mathrm{var}(X). \]</span>
This makes sense. If we multiply all observations by <span class="math inline">\(a\)</span> their variance, which is measured square units, will be multiplied by <span class="math inline">\(a^2\)</span>. If we add <span class="math inline">\(b\)</span> to all observations their variance will be unchanged because the distribution simply shifts up by <span class="math inline">\(b\)</span> and its spread is unaffected.</li>
<li>If <span class="math inline">\(X\)</span> is a constant <span class="math inline">\(c\)</span>, that is, <span class="math inline">\(P(X=c)=1\)</span> then <span class="math inline">\(\mathrm{var}(X)=0\)</span>: the distribution of <span class="math inline">\(X\)</span> has zero spread.</li>
<li>It can also be shown that <strong>if the random variables <span class="math inline">\(X_1, X_2, \ldots X_n\)</span> are independent</strong> (see <strong>An Aside</strong> below) then</li>
</ul>
<p><span class="math display" id="eq:varsum">\[\begin{equation}
\mathrm{var}(X_1 + X_2 + \cdots + X_n) = \mathrm{var}(X_1) + \mathrm{var}(X_2) + \cdots + \mathrm{var}(X_n).
\tag{5.8}
\end{equation}\]</span></p>
<p><strong>Note</strong>. Independence is sufficient for this result to hold but it is not necessary. Taking <span class="math inline">\(n=2\)</span> as an example, in generality we have
<span class="math display">\[ \mathrm{var}(X_1 + X_2) = \mathrm{var}(X_1) + \mathrm{var}(X_2) + 2\,\mathrm{cov}(X_1,X_2), \]</span>
where <span class="math inline">\(\mathrm{cov}(X_1,X_2)\)</span> is the <strong>covariance</strong> between the random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. Covariance is a measure of the strength of <strong>linear</strong> association. If <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent (have no association of any kind) then <span class="math inline">\(\mathrm{cov}(X_1,X_2)=0\)</span>, because they have no linear association. However, it is possible for <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> to be dependent but <span class="math inline">\(\mathrm{cov}(X_1,X_2)=0\)</span>, because, although they have some kind of association, they have no <strong>linear</strong> association. Thus, independence is a stronger requirement than zero covariance.</p>
<p>Returning to general <span class="math inline">\(n\)</span> we have
<span class="math display">\[ \mathrm{var}(X_1 + X_2 + \cdots + X_n) = \mathrm{var}(X_1) + \mathrm{var}(X_2) + \cdots + \mathrm{var}(X_n) + 2 \mathop{\sum\sum}_{i &lt; j} \mathrm{cov}(X_i,X_j). \]</span>
If <span class="math inline">\(\mathrm{cov}(X_i,X_j)=0\)</span> for all <span class="math inline">\(i &lt; j\)</span> then equation <a href="rvs.html#eq:varsum">(5.8)</a> holds. We will study covariance, and its standardised form <strong>correlation</strong>, in Chapter <a href="correlationchapter.html#correlationchapter">10</a>.</p>
<div id="an-aside" class="section level4 hasAnchor" number="5.4.4.1">
<h4><span class="header-section-number">5.4.4.1</span> An aside<a href="rvs.html#an-aside" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>(This is beyond the scope of STAT0002. It is included here for completeness and in case you are interested.) To consider more formally what it means for random variables <span class="math inline">\(X_1, ..., X_n\)</span> to be independent we define their <strong>joint c.d.f.</strong> <span class="math inline">\(F_{X_1, ..., X_n}(x_1, ..., x_n) = P(X_1 \leq x_1, ..., X_n \leq x_n)\)</span>. The random variables <span class="math inline">\(X_1, ..., X_n\)</span> are (mutually) independent if <span class="math inline">\(F_{X_1, ..., X_n}(x_1, ..., x_n) = F_{X_1}(x_1) \times \cdots \times F_{X_n}(x_n)\)</span>, that is, <span class="math inline">\(P(X_1 \leq x_1, ..., X_n \leq x_n) = P(X_1 \leq x_1) \times \cdots \times P(X_n \leq x_n)\)</span>, for any set of values <span class="math inline">\((x_1, .., x_n)\)</span>. The random variables <span class="math inline">\(X_1, ..., X_n\)</span> are pairwise independent if, <span class="math inline">\(F_{X_i, X_j}(x_i, x_j) = F_{X_i}(x_i) F_{X_j}(x_j)\)</span>, that is, <span class="math inline">\(P(X_i \leq x_i, X_j \leq x_j) = P(X_i \leq x_i) P(X_j \leq x_j)\)</span>, for every pair <span class="math inline">\((X_i, X_j)\)</span> of variables that we could select from <span class="math inline">\(X_1, ..., X_n\)</span> and for any pair of values <span class="math inline">\((x_i, x_j)\)</span>.</p>
</div>
</div>
</div>
<div id="locations" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Other measures of location<a href="rvs.html#locations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="the-median-of-a-random-variable" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> The median of a random variable<a href="rvs.html#the-median-of-a-random-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that the sample median of a set of observations is the middle observation when the observations are arranged in order of size. We define the median of a random variable <span class="math inline">\(X\)</span> as a value, median(<span class="math inline">\(X\)</span>), such that</p>
<p><span class="math display">\[ P(X &lt; \mathrm{median}(X)) \leq \frac12 \leq P(X \leq \mathrm{median}(X)). \]</span></p>
<p>In other words, <span class="math inline">\(\mathrm{median}(X)\)</span> is a value where a plot of the c.d.f. <span class="math inline">\(F_X(x)=P(X \leq x)\)</span> hits <span class="math inline">\(1/2\)</span>.</p>
<p>For a continuous random variable <span class="math inline">\(X\)</span> we have
<span class="math display">\[  F_X(\mathrm{median}(X)) = P(X \leq \mathrm{median}(X)) =\frac12. \]</span>
and a median will divide the distribution into two parts, each with probability 1/2:
<span class="math display">\[ P(X &lt; \mathrm{median}(X)) = P(X &gt; \mathrm{median}(X)) = \frac12. \]</span></p>
<p>This will not necessarily hold for a discrete distribution. For example, suppose that
<span class="math display">\[ P(X=0)=\frac16, \qquad  P(X=1)=\frac12, \qquad P(X=2)=\frac13. \]</span></p>
<p>Then
<span class="math display">\[\begin{eqnarray*}
F_X(x) = P(X \leq x) = \left\{\begin{array}{ll}
0 &amp; \mbox{for } x &lt;0, \\
\frac16 &amp; \mbox{for } 0 \leq x &lt; 1, \\
\frac23 &amp; \mbox{for } 1 \leq x &lt; 2, \\
1 &amp; \mbox{for } x \geq 2,
\end{array}\right.
\end{eqnarray*}\]</span></p>
<p>Figure <a href="rvs.html#fig:discretecdf">5.4</a> is a plot of the c.d.f. of this discrete random variable.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:discretecdf"></span>
<img src="stat0002book_files/figure-html/discretecdf-1.png" alt="Plot of the c.d.f. of a discrete random variable that takes the values {0, 1, 2} with respective probabilities {1/6, 1/2, 1/3}. The dashed lines indicate the location of the median (1)." width="75%" />
<p class="caption">
Figure 5.4: Plot of the c.d.f. of a discrete random variable that takes the values {0, 1, 2} with respective probabilities {1/6, 1/2, 1/3}. The dashed lines indicate the location of the median (1).
</p>
</div>
<p>Therefore, <span class="math inline">\(\mathrm{median}(X) = 1\)</span>. However, <span class="math inline">\(P(X&lt;1)=\frac16\)</span> and <span class="math inline">\(P(X&gt;1)=\frac13\)</span>.</p>
</div>
<div id="the-mode-of-a-random-variable" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> The mode of a random variable<a href="rvs.html#the-mode-of-a-random-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that the sample mode of categorical or discrete data is the value (or values) which occurs most often. We define the mode, mode(<span class="math inline">\(X\)</span>), of a random variable as follows.</p>
<p>For a discrete random variable <span class="math inline">\(X\)</span>, the mode is the value which has the highest probability of occurring: <span class="math inline">\(P(X=\mathrm{mode}(X))\)</span> will be larger than for any other value <span class="math inline">\(X\)</span> can have. In other words, <span class="math inline">\(\mathrm{mode}(X)\)</span> is the value at which the p.m.f. is maximised.</p>
<p>For a continuous random variable <span class="math inline">\(X\)</span>, the mode is the value at which the p.d.f. is maximised. <strong>If the maximum occurs at a turning point of <span class="math inline">\(f_X(x)\)</span></strong> then it can be found by solving the equation
<span class="math display">\[ \frac{\mathrm{d}}{\mathrm{d}x} f_X(x)  = 0, \]</span>
and checking that you have indeed found a maximum.</p>
</div>
</div>
<div id="quantiles" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Quantiles<a href="rvs.html#quantiles" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To keep things simple we consider a <strong>continuous</strong> random variable <span class="math inline">\(X\)</span>. For <span class="math inline">\(0 &lt; p &lt; 1\)</span>, a <span class="math inline">\(100p\%\)</span> quantile of <span class="math inline">\(X\)</span> is defined to be a value <span class="math inline">\(x_p\)</span> such that
<span class="math display">\[ F_X(x_p)=P(X \leq x_p) = p. \]</span>
Another way to express this is to say that <span class="math inline">\(x_p\)</span> is <span class="math inline">\(F_X^{-1}(p)\)</span>, where <span class="math inline">\(F_X^{-1}\)</span> is the inverse c.d.f. of <span class="math inline">\(X\)</span>. The inverse c.d.f. <span class="math inline">\(F_X^{-1}\)</span> is also called the quantile function <span class="math inline">\(Q\)</span> of <span class="math inline">\(X\)</span>, so we could write <span class="math inline">\(x_p = Q(p)\)</span>.</p>
<p>Thus, <span class="math inline">\(x_{1/4}=F_X^{-1}(1/4)\)</span> is the lower quartile of <span class="math inline">\(X\)</span>, <span class="math inline">\(x_{1/2}=F_X^{-1}(1/2)\)</span> is the median of <span class="math inline">\(X\)</span> and <span class="math inline">\(x_{3/4}=F_X^{-1}(3/4)\)</span> is the upper quartile of <span class="math inline">\(X\)</span>.</p>
<p>The inter-quartile range is <span class="math inline">\(x_{3/4}-x_{1/4}=F_X^{-1}(3/4)-F_X^{-1}(1/4)\)</span>, which is a measure of spread.</p>
</div>
<div id="measures-of-shape" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Measures of shape<a href="rvs.html#measures-of-shape" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <strong>moment coefficient of skewness</strong> of a random variable <span class="math inline">\(X\)</span> with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> is given by
<span class="math display">\[ \mathrm{E}\left[\left(\frac{X - \mu}{\sigma}\right)^3\right] = \displaystyle\frac{\mathrm{E}\left[\left(X- \mu\right)^3\right]}{\sigma^3}, \]</span>
provided that <span class="math inline">\(\mathrm{E}[\left(X- \mu\right)^3]\)</span> exists.</p>
<p>The <strong>quartile skewness</strong> of a random variable <span class="math inline">\(X\)</span> with c.d.f <span class="math inline">\(F_X(x)\)</span> is given by
<span class="math display">\[ \frac{(x_{3/4}-x_{1/2}) - (x_{1/2}-x_{1/4})}{x_{3/4}-x_{1/4}} = \frac{[F^{-1}_X(3/4) - F^{-1}_X(1/2)] - [F^{-1}_X(1/2) - F^{-1}_X(1/4)]}{F^{-1}_X(3/4) - F^{-1}_X(1/4)}. \]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="more-probability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simple.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["stat0002book.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
